# pesquisa_juridica_completa.py - Pesquisa com Extra√ß√£o Completa e Navega√ß√£o Profunda

import os
import time
import random
import requests
from bs4 import BeautifulSoup
from googlesearch import search
from typing import Dict, Any, List
from datetime import datetime
import re
from urllib.parse import urljoin, urlparse

class PesquisaJuridica:
    """
    Pesquisa Jur√≠dica com Extra√ß√£o COMPLETA e Navega√ß√£o PROFUNDA:
    - Extrai conte√∫do integral dos sites (n√£o apenas resumos)
    - Navega profundamente nos sites para encontrar conte√∫do completo
    - Segue links internos quando necess√°rio
    - Extrai textos longos e substanciais
    """
    
    def __init__(self):
        print("üîç Inicializando Pesquisa Jur√≠dica COMPLETA...")
        
        # Configura√ß√µes para extra√ß√£o completa
        self.config = {
            'tamanho_minimo_conteudo': 1000,      # M√≠nimo 1000 caracteres por conte√∫do
            'tamanho_maximo_conteudo': 30000,     # M√°ximo 30000 caracteres por conte√∫do
            'max_sites_por_query': 5,             # M√°ximo 5 sites por query
            'max_paginas_por_site': 7,            # M√°ximo 7 p√°ginas por site
            'timeout_por_pagina': 15,             # 15 segundos por p√°gina
            'delay_entre_paginas': (1, 3),        # 1-3 segundos entre p√°ginas
            'profundidade_navegacao': 2,          # At√© 2 n√≠veis de profundidade
        }
        
        # User agents rotativos
        self.user_agents = [
            'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36',
            'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36',
            'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36',
            'Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:89.0) Gecko/20100101 Firefox/89.0',
            'Mozilla/5.0 (Macintosh; Intel Mac OS X 10.15; rv:89.0) Gecko/20100101 Firefox/89.0'
        ]
        
        # Sites priorit√°rios por tipo
        self.sites_prioritarios = {
            'legislacao': [
                'planalto.gov.br',
                'lexml.gov.br',
                'senado.leg.br',
                'camara.leg.br'
            ],
            'jurisprudencia': [
                'stf.jus.br',
                'stj.jus.br',
                'tst.jus.br',
                'trf1.jus.br',
                'trf2.jus.br',
                'trf3.jus.br',
                'trf4.jus.br',
                'trf5.jus.br'
            ],
            'doutrina': [
                'conjur.com.br',
                'migalhas.com.br',
                'jota.info',
                'jusbrasil.com.br'
            ]
        }
        
        print("‚úÖ Sistema de pesquisa jur√≠dica COMPLETA inicializado")
    
    def pesquisar_fundamentacao_completa(self, fundamentos: List[str], tipo_acao: str) -> Dict[str, Any]:
        """
        Realiza pesquisa completa com extra√ß√£o integral de conte√∫do.
        """
        try:
            print(f"üîç Iniciando pesquisa jur√≠dica COMPLETA para: {fundamentos}")
            print(f"üìã Tipo de a√ß√£o: {tipo_acao}")
            
            inicio_pesquisa = datetime.now()
            
            # Identificar √°rea do direito
            area_direito = self._identificar_area_direito(fundamentos, tipo_acao)
            print(f"üìö √Årea identificada: {area_direito}")
            
            # Realizar pesquisas por tipo
            resultados = {
                'legislacao': self._pesquisar_legislacao_completa(fundamentos, area_direito),
                'jurisprudencia': self._pesquisar_jurisprudencia_completa(fundamentos, area_direito),
                'doutrina': self._pesquisar_doutrina_completa(fundamentos, area_direito)
            }
            
            # Compilar resultados
            resultado_final = self._compilar_resultados_completos(resultados, area_direito)
            
            tempo_total = (datetime.now() - inicio_pesquisa).total_seconds()
            print(f"‚úÖ PESQUISA COMPLETA CONCLU√çDA em {tempo_total:.1f} segundos")
            
            return resultado_final
            
        except Exception as e:
            print(f"‚ùå Erro na pesquisa completa: {e}")
            return self._gerar_resultado_fallback(fundamentos, tipo_acao)
    
    def _pesquisar_legislacao_completa(self, fundamentos: List[str], area_direito: str) -> List[Dict[str, Any]]:
        """
        Pesquisa legisla√ß√£o com extra√ß√£o completa de artigos e dispositivos.
        """
        print("üìö Buscando LEGISLA√á√ÉO (extra√ß√£o completa)...")
        
        resultados = []
        sites_prioritarios = self.sites_prioritarios['legislacao']
        
        # Queries espec√≠ficas para legisla√ß√£o
        queries_legislacao = []
        for fundamento in fundamentos[:3]:  # M√°ximo 3 fundamentos
            for site in sites_prioritarios[:2]:  # M√°ximo 2 sites priorit√°rios
                queries_legislacao.append(f"{fundamento} artigo lei site:{site}")
        
        for query in queries_legislacao:
            print(f"üîç Pesquisando Google: {query}")
            
            try:
                # Buscar URLs no Google
                urls_encontradas = list(search(query, num_results=self.config['max_sites_por_query'], sleep_interval=1))
                
                for url in urls_encontradas:
                    # Extrair conte√∫do completo do site
                    conteudo_completo = self._extrair_conteudo_completo_site(url, 'legislacao')
                    
                    if conteudo_completo and len(conteudo_completo['texto']) >= self.config['tamanho_minimo_conteudo']:
                        resultados.append(conteudo_completo)
                        
                        # Parar se j√° temos conte√∫do suficiente
                        if len(resultados) >= 5:
                            break
                
                # Delay entre queries
                time.sleep(random.uniform(*self.config['delay_entre_paginas']))
                
            except Exception as e:
                print(f"‚ö†Ô∏è Erro na query '{query}': {e}")
                continue
        
        print(f"üìö Legisla√ß√£o encontrada: {len(resultados)} itens completos")
        return resultados
    
    def _pesquisar_jurisprudencia_completa(self, fundamentos: List[str], area_direito: str) -> List[Dict[str, Any]]:
        """
        Pesquisa jurisprud√™ncia com extra√ß√£o completa de ementas e decis√µes.
        """
        print("‚öñÔ∏è Buscando JURISPRUD√äNCIA (extra√ß√£o completa)...")
        
        resultados = []
        sites_prioritarios = self.sites_prioritarios['jurisprudencia']
        
        # Queries espec√≠ficas para jurisprud√™ncia
        queries_jurisprudencia = []
        for fundamento in fundamentos[:3]:
            for site in sites_prioritarios[:3]:  # M√°ximo 3 tribunais
                queries_jurisprudencia.append(f"jurisprud√™ncia {fundamento} site:{site}")
        
        for query in queries_jurisprudencia:
            print(f"üîç Pesquisando Google: {query}")
            
            try:
                urls_encontradas = list(search(query, num_results=self.config['max_sites_por_query'], sleep_interval=1))
                
                for url in urls_encontradas:
                    conteudo_completo = self._extrair_conteudo_completo_site(url, 'jurisprudencia')
                    
                    if conteudo_completo and len(conteudo_completo['texto']) >= self.config['tamanho_minimo_conteudo']:
                        resultados.append(conteudo_completo)
                        
                        if len(resultados) >= 5:
                            break
                
                time.sleep(random.uniform(*self.config['delay_entre_paginas']))
                
            except Exception as e:
                print(f"‚ö†Ô∏è Erro na query '{query}': {e}")
                continue
        
        print(f"‚öñÔ∏è Jurisprud√™ncia encontrada: {len(resultados)} itens completos")
        return resultados
    
    def _pesquisar_doutrina_completa(self, fundamentos: List[str], area_direito: str) -> List[Dict[str, Any]]:
        """
        Pesquisa doutrina com extra√ß√£o completa de artigos e an√°lises.
        """
        print("üìñ Buscando DOUTRINA (extra√ß√£o completa)...")
        
        resultados = []
        sites_prioritarios = self.sites_prioritarios['doutrina']
        
        # Queries espec√≠ficas para doutrina
        queries_doutrina = []
        for fundamento in fundamentos[:3]:
            for site in sites_prioritarios[:2]:
                queries_doutrina.append(f"artigo {fundamento} {area_direito} site:{site}")
        
        for query in queries_doutrina:
            print(f"üîç Pesquisando Google: {query}")
            
            try:
                urls_encontradas = list(search(query, num_results=self.config['max_sites_por_query'], sleep_interval=1))
                
                for url in urls_encontradas:
                    conteudo_completo = self._extrair_conteudo_completo_site(url, 'doutrina')
                    
                    if conteudo_completo and len(conteudo_completo['texto']) >= self.config['tamanho_minimo_conteudo']:
                        resultados.append(conteudo_completo)
                        
                        if len(resultados) >= 5:
                            break
                
                time.sleep(random.uniform(*self.config['delay_entre_paginas']))
                
            except Exception as e:
                print(f"‚ö†Ô∏è Erro na query '{query}': {e}")
                continue
        
        print(f"üìñ Doutrina encontrada: {len(resultados)} itens completos")
        return resultados
    
    def _extrair_conteudo_completo_site(self, url: str, tipo_conteudo: str) -> Dict[str, Any]:
        """
        Extrai conte√∫do COMPLETO de um site, navegando profundamente se necess√°rio.
        """
        print(f"üåê Extraindo conte√∫do COMPLETO de: {url}")
        
        try:
            # Configurar sess√£o
            session = requests.Session()
            session.headers.update({
                'User-Agent': random.choice(self.user_agents),
                'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8',
                'Accept-Language': 'pt-BR,pt;q=0.9,en;q=0.8',
                'Accept-Encoding': 'gzip, deflate',
                'Connection': 'keep-alive',
                'Upgrade-Insecure-Requests': '1'
            })
            
            # Acessar p√°gina principal
            response = session.get(url, timeout=self.config['timeout_por_pagina'])
            response.raise_for_status()
            
            soup = BeautifulSoup(response.content, 'html.parser')
            
            # Extrair conte√∫do da p√°gina principal
            conteudo_principal = self._extrair_texto_pagina(soup, tipo_conteudo)
            
            # Se conte√∫do √© insuficiente, navegar profundamente
            if len(conteudo_principal) < self.config['tamanho_minimo_conteudo']:
                print(f"üìÑ Conte√∫do insuficiente ({len(conteudo_principal)} chars), navegando profundamente...")
                conteudo_adicional = self._navegar_profundamente(session, url, soup, tipo_conteudo)
                conteudo_principal += "\n\n" + conteudo_adicional
            
            # Limpar e formatar texto
            texto_final = self._limpar_texto_completo(conteudo_principal)
            
            # Limitar tamanho m√°ximo
            if len(texto_final) > self.config['tamanho_maximo_conteudo']:
                texto_final = texto_final[:self.config['tamanho_maximo_conteudo']] + "..."
            
            print(f"üìÑ Conte√∫do COMPLETO extra√≠do: {len(texto_final)} caracteres")
            
            return {
                'url': url,
                'tipo': tipo_conteudo,
                'texto': texto_final,
                'tamanho': len(texto_final),
                'titulo': self._extrair_titulo(soup),
                'timestamp': datetime.now().isoformat()
            }
            
        except Exception as e:
            print(f"‚ùå Erro ao extrair conte√∫do completo de {url}: {e}")
            return None
    
    def _navegar_profundamente(self, session: requests.Session, url_base: str, soup: BeautifulSoup, tipo_conteudo: str) -> str:
        """
        Navega profundamente no site para encontrar conte√∫do mais completo.
        """
        print("üîç Navegando profundamente no site...")
        
        conteudo_adicional = ""
        links_relevantes = self._encontrar_links_relevantes(soup, url_base, tipo_conteudo)
        
        for link in links_relevantes[:self.config['max_paginas_por_site']]:
            try:
                print(f"üåê Acessando p√°gina adicional: {link}")
                
                response = session.get(link, timeout=self.config['timeout_por_pagina'])
                response.raise_for_status()
                
                soup_adicional = BeautifulSoup(response.content, 'html.parser')
                texto_adicional = self._extrair_texto_pagina(soup_adicional, tipo_conteudo)
                
                if len(texto_adicional) >= 500:  # M√≠nimo 500 caracteres por p√°gina adicional
                    conteudo_adicional += "\n\n" + texto_adicional
                    print(f"üìÑ Conte√∫do adicional extra√≠do: {len(texto_adicional)} caracteres")
                
                # Delay entre p√°ginas
                time.sleep(random.uniform(*self.config['delay_entre_paginas']))
                
                # Parar se j√° temos conte√∫do suficiente
                if len(conteudo_adicional) >= self.config['tamanho_minimo_conteudo']:
                    break
                    
            except Exception as e:
                print(f"‚ö†Ô∏è Erro ao acessar {link}: {e}")
                continue
        
        return conteudo_adicional
    
    def _encontrar_links_relevantes(self, soup: BeautifulSoup, url_base: str, tipo_conteudo: str) -> List[str]:
        """
        Encontra links relevantes na p√°gina para navega√ß√£o profunda.
        """
        links_relevantes = []
        base_domain = urlparse(url_base).netloc
        
        # Palavras-chave por tipo de conte√∫do
        palavras_chave = {
            'legislacao': ['artigo', 'lei', 'decreto', 'c√≥digo', 'dispositivo', 'par√°grafo'],
            'jurisprudencia': ['ac√≥rd√£o', 'ementa', 'decis√£o', 's√∫mula', 'jurisprud√™ncia', 'tribunal'],
            'doutrina': ['artigo', 'an√°lise', 'coment√°rio', 'doutrina', 'estudo', 'parecer']
        }
        
        palavras_tipo = palavras_chave.get(tipo_conteudo, [])
        
        # Buscar links com texto relevante
        for link in soup.find_all('a', href=True):
            href = link.get('href')
            texto_link = link.get_text().lower()
            
            # Verificar se √© link interno
            if href.startswith('/'):
                url_completa = urljoin(url_base, href)
            elif base_domain in href:
                url_completa = href
            else:
                continue
            
            # Verificar se o texto do link √© relevante
            if any(palavra in texto_link for palavra in palavras_tipo):
                if url_completa not in links_relevantes and url_completa != url_base:
                    links_relevantes.append(url_completa)
        
        return links_relevantes[:10]  # M√°ximo 10 links relevantes
    
    def _extrair_texto_pagina(self, soup: BeautifulSoup, tipo_conteudo: str) -> str:
        """
        Extrai texto completo de uma p√°gina baseado no tipo de conte√∫do.
        """
        texto_extraido = ""
        
        # Estrat√©gias espec√≠ficas por tipo
        if tipo_conteudo == 'legislacao':
            texto_extraido = self._extrair_texto_legislacao(soup)
        elif tipo_conteudo == 'jurisprudencia':
            texto_extraido = self._extrair_texto_jurisprudencia(soup)
        elif tipo_conteudo == 'doutrina':
            texto_extraido = self._extrair_texto_doutrina(soup)
        
        # Fallback: extra√ß√£o geral
        if len(texto_extraido) < 200:
            texto_extraido = self._extrair_texto_geral(soup)
        
        return texto_extraido
    
    def _extrair_texto_legislacao(self, soup: BeautifulSoup) -> str:
        """
        Extrai texto espec√≠fico de p√°ginas de legisla√ß√£o.
        """
        texto = ""
        
        # Buscar por seletores espec√≠ficos de legisla√ß√£o
        seletores_legislacao = [
            '.artigo', '.paragrafo', '.inciso', '.alinea',
            '[class*="artigo"]', '[class*="dispositivo"]',
            '.texto-lei', '.conteudo-lei', '.texto-norma'
        ]
        
        for seletor in seletores_legislacao:
            elementos = soup.select(seletor)
            for elemento in elementos:
                texto += elemento.get_text() + "\n\n"
        
        # Se n√£o encontrou, buscar por padr√µes de artigos
        if len(texto) < 200:
            # Buscar por padr√µes "Art. X" ou "Artigo X"
            for p in soup.find_all(['p', 'div', 'span']):
                texto_p = p.get_text()
                if re.search(r'Art\.?\s*\d+|Artigo\s*\d+', texto_p):
                    texto += texto_p + "\n\n"
        
        return texto
    
    def _extrair_texto_jurisprudencia(self, soup: BeautifulSoup) -> str:
        """
        Extrai texto espec√≠fico de p√°ginas de jurisprud√™ncia.
        """
        texto = ""
        
        # Buscar por seletores espec√≠ficos de jurisprud√™ncia
        seletores_jurisprudencia = [
            '.ementa', '.acordao', '.decisao', '.voto',
            '[class*="ementa"]', '[class*="acordao"]',
            '.texto-decisao', '.conteudo-acordao'
        ]
        
        for seletor in seletores_jurisprudencia:
            elementos = soup.select(seletor)
            for elemento in elementos:
                texto += elemento.get_text() + "\n\n"
        
        # Buscar por padr√µes de jurisprud√™ncia
        if len(texto) < 200:
            for p in soup.find_all(['p', 'div']):
                texto_p = p.get_text()
                if any(palavra in texto_p.lower() for palavra in ['ementa', 'ac√≥rd√£o', 'decis√£o', 'relat√≥rio']):
                    texto += texto_p + "\n\n"
        
        return texto
    
    def _extrair_texto_doutrina(self, soup: BeautifulSoup) -> str:
        """
        Extrai texto espec√≠fico de p√°ginas de doutrina.
        """
        texto = ""
        
        # Buscar por seletores espec√≠ficos de artigos doutrin√°rios
        seletores_doutrina = [
            '.artigo-conteudo', '.texto-artigo', '.conteudo-principal',
            '[class*="content"]', '[class*="article"]',
            '.post-content', '.entry-content'
        ]
        
        for seletor in seletores_doutrina:
            elementos = soup.select(seletor)
            for elemento in elementos:
                # Remover elementos indesejados
                for tag_indesejada in elemento.find_all(['script', 'style', 'nav', 'footer', 'header']):
                    tag_indesejada.decompose()
                
                texto += elemento.get_text() + "\n\n"
        
        return texto
    
    def _extrair_texto_geral(self, soup: BeautifulSoup) -> str:
        """
        Extra√ß√£o geral de texto quando m√©todos espec√≠ficos falham.
        """
        # Remover elementos indesejados
        for tag in soup.find_all(['script', 'style', 'nav', 'footer', 'header', 'aside']):
            tag.decompose()
        
        # Buscar por conte√∫do principal
        conteudo_principal = soup.find('main') or soup.find('article') or soup.find('body')
        
        if conteudo_principal:
            return conteudo_principal.get_text()
        else:
            return soup.get_text()
    
    def _extrair_titulo(self, soup: BeautifulSoup) -> str:
        """
        Extrai t√≠tulo da p√°gina.
        """
        titulo = soup.find('title')
        if titulo:
            return titulo.get_text().strip()
        
        h1 = soup.find('h1')
        if h1:
            return h1.get_text().strip()
        
        return "T√≠tulo n√£o encontrado"
    
    def _limpar_texto_completo(self, texto: str) -> str:
        """
        Limpa e formata texto extra√≠do mantendo conte√∫do completo.
        """
        if not texto:
            return ""
        
        # Remover caracteres especiais problem√°ticos
        texto = re.sub(r'[^\w\s\.\,\;\:\!\?\(\)\[\]\-\+\=\%\$\@\#\n]', ' ', texto)
        
        # Normalizar espa√ßos
        texto = re.sub(r'\s+', ' ', texto)
        
        # Normalizar quebras de linha
        texto = re.sub(r'\n+', '\n', texto)
        
        # Remover linhas muito curtas (menos de 10 caracteres)
        linhas = texto.split('\n')
        linhas_filtradas = [linha.strip() for linha in linhas if len(linha.strip()) >= 10]
        
        return '\n'.join(linhas_filtradas).strip()
    
    def _identificar_area_direito(self, fundamentos: List[str], tipo_acao: str) -> str:
        """
        Identifica √°rea do direito baseada nos fundamentos.
        """
        fundamentos_texto = ' '.join(fundamentos).lower()
        tipo_acao_lower = tipo_acao.lower()
        
        if any(palavra in fundamentos_texto or palavra in tipo_acao_lower 
               for palavra in ['trabalho', 'trabalhista', 'clt', 'emprego']):
            return 'trabalhista'
        elif any(palavra in fundamentos_texto or palavra in tipo_acao_lower 
                 for palavra in ['consumidor', 'cdc', 'fornecedor']):
            return 'consumidor'
        elif any(palavra in fundamentos_texto or palavra in tipo_acao_lower 
                 for palavra in ['civil', 'contrato', 'responsabilidade']):
            return 'civil'
        else:
            return 'geral'
    
    def _compilar_resultados_completos(self, resultados: Dict[str, List], area_direito: str) -> Dict[str, Any]:
        """
        Compila resultados completos da pesquisa.
        """
        # Contar totais
        total_legislacao = len(resultados['legislacao'])
        total_jurisprudencia = len(resultados['jurisprudencia'])
        total_doutrina = len(resultados['doutrina'])
        total_sites = total_legislacao + total_jurisprudencia + total_doutrina
        
        # Compilar todos os conte√∫dos
        todos_conteudos = []
        todos_conteudos.extend(resultados['legislacao'])
        todos_conteudos.extend(resultados['jurisprudencia'])
        todos_conteudos.extend(resultados['doutrina'])
        
        # Gerar textos formatados completos
        legislacao_formatada = self._formatar_legislacao_completa(resultados['legislacao'])
        jurisprudencia_formatada = self._formatar_jurisprudencia_completa(resultados['jurisprudencia'])
        doutrina_formatada = self._formatar_doutrina_completa(resultados['doutrina'])
        
        print(f"üåê Total de sites acessados: {total_sites}")
        print(f"üìÑ Total de conte√∫dos extra√≠dos: {len(todos_conteudos)}")
        
        return {
            "status": "sucesso",
            "area_direito": area_direito,
            "legislacao_formatada": legislacao_formatada,
            "jurisprudencia_formatada": jurisprudencia_formatada,
            "doutrina_formatada": doutrina_formatada,
            "conteudos_extraidos": todos_conteudos,
            "sites_acessados": [conteudo['url'] for conteudo in todos_conteudos],
            "estatisticas": {
                "total_sites_acessados": total_sites,
                "total_conteudos_extraidos": len(todos_conteudos),
                "legislacao_encontrada": total_legislacao,
                "jurisprudencia_encontrada": total_jurisprudencia,
                "doutrina_encontrada": total_doutrina,
                "caracteres_totais_extraidos": sum(conteudo['tamanho'] for conteudo in todos_conteudos)
            },
            "timestamp": datetime.now().isoformat()
        }
    
    def _formatar_legislacao_completa(self, legislacao: List[Dict[str, Any]]) -> str:
        """
        Formata legisla√ß√£o com conte√∫do completo.
        """
        if not legislacao:
            return "Legisla√ß√£o espec√≠fica n√£o encontrada nas pesquisas realizadas."
        
        texto_formatado = "LEGISLA√á√ÉO APLIC√ÅVEL (CONTE√öDO COMPLETO):\n\n"
        
        for i, item in enumerate(legislacao, 1):
            texto_formatado += f"DISPOSITIVO LEGAL {i}:\n"
            texto_formatado += f"Fonte: {item['titulo']}\n"
            texto_formatado += f"Conte√∫do Integral:\n{item['texto']}\n"
            texto_formatado += "-" * 80 + "\n\n"
        
        return texto_formatado
    
    def _formatar_jurisprudencia_completa(self, jurisprudencia: List[Dict[str, Any]]) -> str:
        """
        Formata jurisprud√™ncia com conte√∫do completo.
        """
        if not jurisprudencia:
            return "Jurisprud√™ncia espec√≠fica n√£o encontrada nas pesquisas realizadas."
        
        texto_formatado = "JURISPRUD√äNCIA DOS TRIBUNAIS SUPERIORES (CONTE√öDO COMPLETO):\n\n"
        
        for i, item in enumerate(jurisprudencia, 1):
            texto_formatado += f"PRECEDENTE JUDICIAL {i}:\n"
            texto_formatado += f"Tribunal: {item['titulo']}\n"
            texto_formatado += f"Decis√£o Completa:\n{item['texto']}\n"
            texto_formatado += "-" * 80 + "\n\n"
        
        return texto_formatado
    
    def _formatar_doutrina_completa(self, doutrina: List[Dict[str, Any]]) -> str:
        """
        Formata doutrina com conte√∫do completo.
        """
        if not doutrina:
            return "Doutrina espec√≠fica n√£o encontrada nas pesquisas realizadas."
        
        texto_formatado = "DOUTRINA ESPECIALIZADA (CONTE√öDO COMPLETO):\n\n"
        
        for i, item in enumerate(doutrina, 1):
            texto_formatado += f"AN√ÅLISE DOUTRIN√ÅRIA {i}:\n"
            texto_formatado += f"Fonte: {item['titulo']}\n"
            texto_formatado += f"Conte√∫do Integral:\n{item['texto']}\n"
            texto_formatado += "-" * 80 + "\n\n"
        
        return texto_formatado
    
    def _gerar_resultado_fallback(self, fundamentos: List[str], tipo_acao: str) -> Dict[str, Any]:
        """
        Gera resultado fallback quando pesquisa falha.
        """
        return {
            "status": "fallback",
            "area_direito": "geral",
            "legislacao_formatada": "Legisla√ß√£o aplic√°vel n√£o p√¥de ser pesquisada no momento.",
            "jurisprudencia_formatada": "Jurisprud√™ncia aplic√°vel n√£o p√¥de ser pesquisada no momento.",
            "doutrina_formatada": "Doutrina aplic√°vel n√£o p√¥de ser pesquisada no momento.",
            "conteudos_extraidos": [],
            "sites_acessados": [],
            "estatisticas": {
                "total_sites_acessados": 0,
                "total_conteudos_extraidos": 0,
                "legislacao_encontrada": 0,
                "jurisprudencia_encontrada": 0,
                "doutrina_encontrada": 0,
                "caracteres_totais_extraidos": 0
            },
            "timestamp": datetime.now().isoformat()
        }