# pesquisa_juridica.py - Pesquisa Real com Google Search API

import re
import time
import random
import requests
from typing import Dict, List, Any, Tuple
from bs4 import BeautifulSoup
import urllib.parse

# FERRAMENTA REAL 1: Google Search Python (biblioteca espec√≠fica)
try:
    from googlesearch import search
    GOOGLE_SEARCH_AVAILABLE = True
    print("‚úÖ Google Search Python dispon√≠vel")
except ImportError:
    GOOGLE_SEARCH_AVAILABLE = False
    print("‚ö†Ô∏è Google Search Python n√£o dispon√≠vel. Instale com: pip install googlesearch-python")

# FERRAMENTA REAL 2: Requests para acessar sites encontrados
# FERRAMENTA REAL 3: BeautifulSoup para extrair conte√∫do real

class PesquisaJuridica:
    """
    M√≥dulo de pesquisa jur√≠dica que usa Google Search API real
    e extrai conte√∫do verdadeiro dos sites encontrados.
    NUNCA usa dados simulados - sempre dados reais dos formul√°rios + pesquisas.
    """
    
    def __init__(self):
        # CONFIGURA√á√ÉO 1: User agents realistas para evitar bloqueios
        self.user_agents = [
            'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
            'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
            'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/119.0.0.0 Safari/537.36',
            'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
            'Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:109.0) Gecko/20100101 Firefox/121.0'
        ]
        
        # CONFIGURA√á√ÉO 2: Delays para evitar rate limits
        self.delay_entre_buscas = (3, 7)  # 3-7 segundos entre buscas Google
        self.delay_entre_sites = (2, 4)   # 2-4 segundos entre acessos a sites
        self.timeout_site = 20             # 20 segundos timeout por site
        self.max_sites_por_busca = 5       # M√°ximo 5 sites por busca
        self.min_conteudo_util = 200       # M√≠nimo 200 chars de conte√∫do √∫til
        
        # CONFIGURA√á√ÉO 3: Sites priorit√°rios REAIS para cada categoria
        self.sites_oficiais = {
            'legislacao': [
                'planalto.gov.br',
                'lexml.gov.br',
                'senado.leg.br',
                'camara.leg.br',
                'presidencia.gov.br'
            ],
            'jurisprudencia': [
                'stf.jus.br',
                'stj.jus.br',
                'tst.jus.br',
                'tjsp.jus.br',
                'tjrj.jus.br',
                'tjmg.jus.br'
            ],
            'doutrina': [
                'conjur.com.br',
                'migalhas.com.br',
                'jota.info',
                'jusbrasil.com.br',
                'direitonet.com.br'
            ]
        }
        
        print("üîç Sistema de pesquisa jur√≠dica REAL inicializado")
        print(f"üìö Google Search: {'‚úÖ Dispon√≠vel' if GOOGLE_SEARCH_AVAILABLE else '‚ùå Indispon√≠vel'}")
    
    def pesquisar_fundamentos_juridicos(self, fundamentos: List[str], tipo_acao: str) -> Dict[str, Any]:
        """
        Realiza pesquisa jur√≠dica REAL usando Google Search API
        e extrai conte√∫do verdadeiro dos sites encontrados.
        NUNCA retorna dados simulados.
        """
        try:
            print(f"üîç INICIANDO PESQUISA REAL para: {fundamentos}")
            print(f"üìã Tipo de a√ß√£o: {tipo_acao}")
            
            if not GOOGLE_SEARCH_AVAILABLE:
                raise Exception("Google Search Python n√£o est√° dispon√≠vel. Instale com: pip install googlesearch-python")
            
            # ETAPA 1: Pesquisar legisla√ß√£o REAL
            print("üìö Buscando LEGISLA√á√ÉO REAL...")
            leis_reais = self._buscar_legislacao_real(fundamentos, tipo_acao)
            
            # ETAPA 2: Pesquisar jurisprud√™ncia REAL  
            print("‚öñÔ∏è Buscando JURISPRUD√äNCIA REAL...")
            jurisprudencia_real = self._buscar_jurisprudencia_real(fundamentos, tipo_acao)
            
            # ETAPA 3: Pesquisar doutrina REAL
            print("üìñ Buscando DOUTRINA REAL...")
            doutrina_real = self._buscar_doutrina_real(fundamentos, tipo_acao)
            
            # ETAPA 4: Compilar resultados REAIS
            resultados = {
                "leis": leis_reais,
                "jurisprudencia": jurisprudencia_real,
                "doutrina": doutrina_real,
                "resumo_pesquisa": self._gerar_resumo_real(leis_reais, jurisprudencia_real, doutrina_real, fundamentos, tipo_acao)
            }
            
            print("‚úÖ PESQUISA REAL CONCLU√çDA")
            return resultados
            
        except Exception as e:
            print(f"‚ùå ERRO CR√çTICO na pesquisa real: {e}")
            # NUNCA retornar dados simulados - falhar explicitamente
            raise Exception(f"Falha na pesquisa jur√≠dica real: {str(e)}. Sistema configurado para NUNCA usar dados simulados.")
    
    def _buscar_legislacao_real(self, fundamentos: List[str], tipo_acao: str) -> str:
        """Busca legisla√ß√£o REAL usando Google Search API."""
        try:
            conteudo_legislacao = []
            
            for fundamento in fundamentos[:2]:  # M√°ximo 2 fundamentos para n√£o sobrecarregar
                # QUERY REAL 1: Busca espec√≠fica no Planalto
                query1 = f"lei {fundamento} site:planalto.gov.br"
                sites_encontrados = self._google_search_real(query1)
                
                for site_url in sites_encontrados[:3]:  # Top 3 sites por query
                    conteudo = self._extrair_conteudo_real(site_url, 'legislacao')
                    if conteudo and len(conteudo) > self.min_conteudo_util:
                        conteudo_legislacao.append(conteudo)
                
                # Delay entre buscas
                time.sleep(random.uniform(*self.delay_entre_buscas))
                
                # QUERY REAL 2: Busca geral de legisla√ß√£o
                query2 = f"c√≥digo {fundamento} legisla√ß√£o federal"
                sites_encontrados = self._google_search_real(query2)
                
                for site_url in sites_encontrados[:2]:  # Top 2 sites da segunda query
                    conteudo = self._extrair_conteudo_real(site_url, 'legislacao')
                    if conteudo and len(conteudo) > self.min_conteudo_util:
                        conteudo_legislacao.append(conteudo)
                
                time.sleep(random.uniform(*self.delay_entre_buscas))
            
            if conteudo_legislacao:
                resultado_final = "LEGISLA√á√ÉO ENCONTRADA (FONTES REAIS):\n\n"
                resultado_final += "\n\n" + "="*80 + "\n\n".join(conteudo_legislacao[:4])  # M√°ximo 4 fontes
                return resultado_final
            else:
                raise Exception("Nenhuma legisla√ß√£o real encontrada nos sites oficiais")
                
        except Exception as e:
            print(f"‚ùå Erro na busca de legisla√ß√£o real: {e}")
            raise Exception(f"Falha na busca de legisla√ß√£o: {str(e)}")
    
    def _buscar_jurisprudencia_real(self, fundamentos: List[str], tipo_acao: str) -> str:
        """Busca jurisprud√™ncia REAL usando Google Search API."""
        try:
            conteudo_jurisprudencia = []
            
            for fundamento in fundamentos[:2]:
                # QUERY REAL 1: STJ
                query1 = f"ac√≥rd√£o {fundamento} site:stj.jus.br"
                sites_encontrados = self._google_search_real(query1)
                
                for site_url in sites_encontrados[:2]:
                    conteudo = self._extrair_conteudo_real(site_url, 'jurisprudencia')
                    if conteudo and len(conteudo) > self.min_conteudo_util:
                        conteudo_jurisprudencia.append(conteudo)
                
                time.sleep(random.uniform(*self.delay_entre_buscas))
                
                # QUERY REAL 2: STF
                query2 = f"decis√£o {fundamento} site:stf.jus.br"
                sites_encontrados = self._google_search_real(query2)
                
                for site_url in sites_encontrados[:2]:
                    conteudo = self._extrair_conteudo_real(site_url, 'jurisprudencia')
                    if conteudo and len(conteudo) > self.min_conteudo_util:
                        conteudo_jurisprudencia.append(conteudo)
                
                time.sleep(random.uniform(*self.delay_entre_buscas))
            
            if conteudo_jurisprudencia:
                resultado_final = "JURISPRUD√äNCIA ENCONTRADA (TRIBUNAIS REAIS):\n\n"
                resultado_final += "\n\n" + "="*80 + "\n\n".join(conteudo_jurisprudencia[:4])
                return resultado_final
            else:
                raise Exception("Nenhuma jurisprud√™ncia real encontrada nos tribunais")
                
        except Exception as e:
            print(f"‚ùå Erro na busca de jurisprud√™ncia real: {e}")
            raise Exception(f"Falha na busca de jurisprud√™ncia: {str(e)}")
    
    def _buscar_doutrina_real(self, fundamentos: List[str], tipo_acao: str) -> str:
        """Busca doutrina REAL usando Google Search API."""
        try:
            conteudo_doutrina = []
            
            for fundamento in fundamentos[:2]:
                # QUERY REAL 1: Conjur
                query1 = f"artigo {fundamento} site:conjur.com.br"
                sites_encontrados = self._google_search_real(query1)
                
                for site_url in sites_encontrados[:2]:
                    conteudo = self._extrair_conteudo_real(site_url, 'doutrina')
                    if conteudo and len(conteudo) > self.min_conteudo_util:
                        conteudo_doutrina.append(conteudo)
                
                time.sleep(random.uniform(*self.delay_entre_buscas))
                
                # QUERY REAL 2: Migalhas
                query2 = f"coment√°rio {fundamento} site:migalhas.com.br"
                sites_encontrados = self._google_search_real(query2)
                
                for site_url in sites_encontrados[:2]:
                    conteudo = self._extrair_conteudo_real(site_url, 'doutrina')
                    if conteudo and len(conteudo) > self.min_conteudo_util:
                        conteudo_doutrina.append(conteudo)
                
                time.sleep(random.uniform(*self.delay_entre_buscas))
            
            if conteudo_doutrina:
                resultado_final = "DOUTRINA ENCONTRADA (ARTIGOS REAIS):\n\n"
                resultado_final += "\n\n" + "="*80 + "\n\n".join(conteudo_doutrina[:4])
                return resultado_final
            else:
                raise Exception("Nenhuma doutrina real encontrada nos sites especializados")
                
        except Exception as e:
            print(f"‚ùå Erro na busca de doutrina real: {e}")
            raise Exception(f"Falha na busca de doutrina: {str(e)}")
    
    def _google_search_real(self, query: str) -> List[str]:
        """
        Usa Google Search Python para busca REAL.
        FERRAMENTA: googlesearch-python
        """
        try:
            print(f"üåê Google Search REAL: {query}")
            
            # BUSCA REAL usando googlesearch-python
            resultados = []
            
            # search() retorna URLs reais do Google
            for url in search(query, num_results=self.max_sites_por_busca, sleep_interval=2):
                if url and url.startswith('http'):
                    resultados.append(url)
                    print(f"üìã Encontrado: {url}")
            
            print(f"‚úÖ {len(resultados)} URLs reais encontradas")
            return resultados
            
        except Exception as e:
            print(f"‚ùå Erro na busca Google real: {e}")
            return []
    
    def _extrair_conteudo_real(self, url: str, tipo_conteudo: str) -> str:
        """
        Acessa URL real e extrai conte√∫do verdadeiro.
        FERRAMENTA: requests + BeautifulSoup
        """
        try:
            print(f"üìÑ Acessando site REAL: {url}")
            
            headers = {
                'User-Agent': random.choice(self.user_agents),
                'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8',
                'Accept-Language': 'pt-BR,pt;q=0.9,en;q=0.8',
                'Accept-Encoding': 'gzip, deflate, br',
                'Connection': 'keep-alive',
                'Upgrade-Insecure-Requests': '1',
                'Cache-Control': 'max-age=0'
            }
            
            # ACESSO REAL ao site
            response = requests.get(url, headers=headers, timeout=self.timeout_site)
            
            if response.status_code == 200:
                # EXTRA√á√ÉO REAL do conte√∫do
                soup = BeautifulSoup(response.content, 'html.parser')
                
                if tipo_conteudo == 'legislacao':
                    conteudo_extraido = self._extrair_legislacao_real(soup, url)
                elif tipo_conteudo == 'jurisprudencia':
                    conteudo_extraido = self._extrair_jurisprudencia_real(soup, url)
                elif tipo_conteudo == 'doutrina':
                    conteudo_extraido = self._extrair_doutrina_real(soup, url)
                else:
                    conteudo_extraido = self._extrair_conteudo_generico_real(soup, url)
                
                # Delay entre acessos
                time.sleep(random.uniform(*self.delay_entre_sites))
                
                if conteudo_extraido and len(conteudo_extraido) > self.min_conteudo_util:
                    print(f"‚úÖ Conte√∫do REAL extra√≠do: {len(conteudo_extraido)} caracteres")
                    return conteudo_extraido
                else:
                    print(f"‚ö†Ô∏è Conte√∫do insuficiente extra√≠do")
                    return None
            else:
                print(f"‚ö†Ô∏è Site retornou status {response.status_code}")
                return None
                
        except Exception as e:
            print(f"‚ùå Erro ao acessar site real {url}: {e}")
            return None
    
    def _extrair_legislacao_real(self, soup: BeautifulSoup, url: str) -> str:
        """Extrai conte√∫do REAL de legisla√ß√£o."""
        try:
            elementos_reais = []
            
            # T√çTULO REAL da lei
            titulo = soup.find('h1') or soup.find('title')
            if titulo:
                titulo_texto = titulo.get_text().strip()
                if len(titulo_texto) > 10:
                    elementos_reais.append(f"T√çTULO: {titulo_texto}")
            
            # ARTIGOS REAIS da legisla√ß√£o
            # Buscar por padr√µes t√≠picos de artigos de lei
            artigos_encontrados = soup.find_all(text=re.compile(r'Art\.\s*\d+|Artigo\s*\d+'))
            for artigo_texto in artigos_encontrados[:5]:  # M√°ximo 5 artigos
                # Pegar o par√°grafo completo que cont√©m o artigo
                elemento_pai = artigo_texto.parent
                if elemento_pai:
                    texto_completo = elemento_pai.get_text().strip()
                    if len(texto_completo) > 50 and len(texto_completo) < 1000:
                        elementos_reais.append(f"ARTIGO: {texto_completo}")
            
            # PAR√ÅGRAFOS REAIS com conte√∫do jur√≠dico
            paragrafos = soup.find_all('p')
            for p in paragrafos[:10]:
                texto = p.get_text().strip()
                # Filtrar par√°grafos que parecem ser conte√∫do jur√≠dico real
                if (len(texto) > 100 and 
                    any(palavra in texto.lower() for palavra in ['lei', 'c√≥digo', 'decreto', 'artigo', 'par√°grafo', 'inciso']) and
                    not any(palavra in texto.lower() for palavra in ['cookie', 'publicidade', 'newsletter', 'login'])):
                    elementos_reais.append(f"DISPOSITIVO: {texto}")
            
            if elementos_reais:
                resultado = "\n\n".join(elementos_reais[:6])  # M√°ximo 6 elementos
                resultado += f"\n\nFONTE OFICIAL: {url}"
                resultado += f"\nDATA DE ACESSO: {time.strftime('%d/%m/%Y %H:%M')}"
                return resultado
            
            return None
            
        except Exception as e:
            print(f"‚ùå Erro ao extrair legisla√ß√£o real: {e}")
            return None
    
    def _extrair_jurisprudencia_real(self, soup: BeautifulSoup, url: str) -> str:
        """Extrai conte√∫do REAL de jurisprud√™ncia."""
        try:
            elementos_reais = []
            
            # EMENTA REAL
            ementa_patterns = [
                soup.find(text=re.compile(r'EMENTA', re.IGNORECASE)),
                soup.find('div', class_=re.compile(r'ementa', re.IGNORECASE)),
                soup.find('p', class_=re.compile(r'ementa', re.IGNORECASE))
            ]
            
            for ementa in ementa_patterns:
                if ementa:
                    if hasattr(ementa, 'parent'):
                        texto_ementa = ementa.parent.get_text().strip()
                    else:
                        texto_ementa = str(ementa).strip()
                    
                    if len(texto_ementa) > 100:
                        elementos_reais.append(f"EMENTA: {texto_ementa[:800]}...")
                        break
            
            # RELAT√ìRIO REAL
            relatorio_patterns = [
                soup.find(text=re.compile(r'RELAT√ìRIO|VOTO', re.IGNORECASE)),
                soup.find('div', class_=re.compile(r'relatorio|voto', re.IGNORECASE))
            ]
            
            for relatorio in relatorio_patterns:
                if relatorio:
                    if hasattr(relatorio, 'parent'):
                        texto_relatorio = relatorio.parent.get_text().strip()
                    else:
                        texto_relatorio = str(relatorio).strip()
                    
                    if len(texto_relatorio) > 100:
                        elementos_reais.append(f"RELAT√ìRIO: {texto_relatorio[:600]}...")
                        break
            
            # DECIS√ÉO REAL
            decisao_patterns = [
                soup.find(text=re.compile(r'DECIS√ÉO|ACORDAM|JULGA', re.IGNORECASE)),
                soup.find('div', class_=re.compile(r'decisao|acordao', re.IGNORECASE))
            ]
            
            for decisao in decisao_patterns:
                if decisao:
                    if hasattr(decisao, 'parent'):
                        texto_decisao = decisao.parent.get_text().strip()
                    else:
                        texto_decisao = str(decisao).strip()
                    
                    if len(texto_decisao) > 50:
                        elementos_reais.append(f"DECIS√ÉO: {texto_decisao[:500]}...")
                        break
            
            if elementos_reais:
                resultado = "\n\n".join(elementos_reais)
                resultado += f"\n\nTRIBUNAL: {url}"
                resultado += f"\nDATA DE ACESSO: {time.strftime('%d/%m/%Y %H:%M')}"
                return resultado
            
            return None
            
        except Exception as e:
            print(f"‚ùå Erro ao extrair jurisprud√™ncia real: {e}")
            return None
    
    def _extrair_doutrina_real(self, soup: BeautifulSoup, url: str) -> str:
        """Extrai conte√∫do REAL de doutrina."""
        try:
            elementos_reais = []
            
            # T√çTULO REAL do artigo
            titulo = soup.find('h1') or soup.find('h2', class_=re.compile(r'title|titulo'))
            if titulo:
                titulo_texto = titulo.get_text().strip()
                if len(titulo_texto) > 15:
                    elementos_reais.append(f"ARTIGO: {titulo_texto}")
            
            # AUTOR REAL
            autor_patterns = [
                soup.find('span', class_=re.compile(r'author|autor')),
                soup.find('div', class_=re.compile(r'author|autor')),
                soup.find(text=re.compile(r'Por:|Autor:|By:'))
            ]
            
            for autor in autor_patterns:
                if autor:
                    if hasattr(autor, 'get_text'):
                        texto_autor = autor.get_text().strip()
                    else:
                        texto_autor = str(autor).strip()
                    
                    if len(texto_autor) > 5 and len(texto_autor) < 100:
                        elementos_reais.append(f"AUTOR: {texto_autor}")
                        break
            
            # CONTE√öDO REAL do artigo
            paragrafos = soup.find_all('p')
            conteudo_paragrafos = []
            
            for p in paragrafos:
                texto = p.get_text().strip()
                # Filtrar conte√∫do que parece ser artigo jur√≠dico real
                if (len(texto) > 150 and 
                    not any(palavra in texto.lower() for palavra in ['cookie', 'publicidade', 'newsletter', 'cadastre-se', 'assine']) and
                    any(palavra in texto.lower() for palavra in ['direito', 'lei', 'jur√≠dico', 'tribunal', 'processo', 'c√≥digo'])):
                    conteudo_paragrafos.append(texto)
            
            # Pegar os melhores par√°grafos
            if conteudo_paragrafos:
                elementos_reais.append("CONTE√öDO:")
                for i, paragrafo in enumerate(conteudo_paragrafos[:4], 1):  # M√°ximo 4 par√°grafos
                    elementos_reais.append(f"{i}. {paragrafo[:400]}...")
            
            if elementos_reais:
                resultado = "\n\n".join(elementos_reais)
                resultado += f"\n\nFONTE ESPECIALIZADA: {url}"
                resultado += f"\nDATA DE ACESSO: {time.strftime('%d/%m/%Y %H:%M')}"
                return resultado
            
            return None
            
        except Exception as e:
            print(f"‚ùå Erro ao extrair doutrina real: {e}")
            return None
    
    def _extrair_conteudo_generico_real(self, soup: BeautifulSoup, url: str) -> str:
        """Extrai conte√∫do REAL gen√©rico quando tipo n√£o √© espec√≠fico."""
        try:
            # T√≠tulo
            titulo = soup.find('h1') or soup.find('title')
            titulo_texto = titulo.get_text().strip() if titulo else "Documento Jur√≠dico"
            
            # Par√°grafos com conte√∫do jur√≠dico
            paragrafos = soup.find_all('p')
            conteudo_relevante = []
            
            for p in paragrafos:
                texto = p.get_text().strip()
                if (len(texto) > 100 and 
                    any(palavra in texto.lower() for palavra in ['direito', 'lei', 'jur√≠dico', 'processo', 'tribunal']) and
                    not any(palavra in texto.lower() for palavra in ['cookie', 'publicidade', 'newsletter'])):
                    conteudo_relevante.append(texto[:300] + "...")
            
            if conteudo_relevante:
                resultado = f"DOCUMENTO: {titulo_texto}\n\n"
                resultado += "\n\n".join(conteudo_relevante[:5])
                resultado += f"\n\nFONTE: {url}"
                resultado += f"\nDATA DE ACESSO: {time.strftime('%d/%m/%Y %H:%M')}"
                return resultado
            
            return None
            
        except Exception as e:
            print(f"‚ùå Erro ao extrair conte√∫do gen√©rico real: {e}")
            return None
    
    def _gerar_resumo_real(self, leis: str, jurisprudencia: str, doutrina: str, fundamentos: List[str], tipo_acao: str) -> str:
        """Gera resumo baseado APENAS em dados reais obtidos."""
        
        # Contar fontes REAIS encontradas
        fontes_leis = leis.count('FONTE OFICIAL:') if leis else 0
        fontes_juris = jurisprudencia.count('TRIBUNAL:') if jurisprudencia else 0
        fontes_doutrina = doutrina.count('FONTE ESPECIALIZADA:') if doutrina else 0
        
        total_fontes_reais = fontes_leis + fontes_juris + fontes_doutrina
        
        return f"""
RESUMO DA PESQUISA JUR√çDICA REAL:

Tipo de A√ß√£o: {tipo_acao}
Fundamentos Pesquisados: {', '.join(fundamentos)}
Total de Fontes REAIS Acessadas: {total_fontes_reais}

METODOLOGIA APLICADA:
- Google Search Python API para busca real
- Acesso direto aos sites oficiais encontrados
- Extra√ß√£o de conte√∫do verdadeiro via BeautifulSoup
- Filtragem de conte√∫do jur√≠dico relevante
- ZERO dados simulados ou fict√≠cios

RESULTADOS REAIS OBTIDOS:
- Legisla√ß√£o: {fontes_leis} fontes oficiais do governo
- Jurisprud√™ncia: {fontes_juris} decis√µes de tribunais reais
- Doutrina: {fontes_doutrina} artigos de sites especializados

GARANTIA DE AUTENTICIDADE:
Todas as informa√ß√µes foram extra√≠das diretamente dos sites
oficiais e especializados em {time.strftime('%d/%m/%Y √†s %H:%M')}.
Nenhum dado foi simulado ou inventado.

FERRAMENTAS UTILIZADAS:
- googlesearch-python (busca real no Google)
- requests (acesso direto aos sites)
- BeautifulSoup (extra√ß√£o de conte√∫do real)
        """

