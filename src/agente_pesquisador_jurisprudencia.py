# agente_pesquisador_jurisprudencia.py - v3.8 (Com Pesquisa Obrigat√≥ria por Dom√≠nio)

import asyncio
import aiohttp
import re
import openai
import os
import random
from datetime import datetime
from typing import Dict, Any, List
from googlesearch import search
from bs4 import BeautifulSoup
from urllib.parse import urlparse

class AgentePesquisadorJurisprudencia:
    """
    Agente Especializado em Pesquisa de Jurisprud√™ncia.
    v3.8: Garante que a pesquisa seja tentada em todos os dom√≠nios priorit√°rios
    e extrai o conte√∫do completo dos artigos encontrados.
    """
    def __init__(self, api_key: str = None):
        print("‚öñÔ∏è  Inicializando Agente de Pesquisa de JURISPRUD√äNCIA (v3.8)...")
        
        if not api_key:
            api_key = os.getenv('DEEPSEEK_API_KEY')
        
        if not api_key:
            raise ValueError("A chave da API da DeepSeek √© necess√°ria para o filtro de relev√¢ncia e n√£o foi encontrada.")
        
        self.client = openai.OpenAI(api_key=api_key, base_url="https://api.deepseek.com/v1")
        
        self.user_agents = [
            "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36",
            "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.114 Safari/537.36",
            "Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:89.0) Gecko/20100101 Firefox/89.0",
            "Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/92.0.4515.107 Safari/537.36"
        ]
        
        self.headers = {
            'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8',
            'Accept-Language': 'pt-BR,pt;q=0.9,en-US;q=0.8,en;q=0.7',
        }
        self.config = {
            'tamanho_minimo_conteudo': 500,
            # COMENT√ÅRIO: A pesquisa agora busca 3 resultados por dom√≠nio, tornando a busca mais distribu√≠da.
            'search_results_per_domain': 3,
        }
        self.sites_prioritarios = ['stj.jus.br', 'stf.jus.br', 'tst.jus.br', 'conjur.com.br', 'migalhas.com.br', 'ambito-juridico.com.br']
        print("‚úÖ Sistema de pesquisa de JURISPRUD√äNCIA inicializado.")

    async def _validar_relevancia_com_ia_async(self, texto: str, termo_pesquisa: str) -> bool:
        """Usa a IA da DeepSeek para validar se o conte√∫do extra√≠do √© relevante."""
        try:
            prompt = f"""
            Analise o seguinte texto e determine se ele √© uma JURISPRUD√äNCIA (decis√£o judicial, ac√≥rd√£o, ementa) relevante para o termo de pesquisa "{termo_pesquisa}".
            Responda APENAS com "SIM" se for uma jurisprud√™ncia relevante, ou "N√ÉO" caso contr√°rio.

            TEXTO PARA AN√ÅLISE:
            ---
            {texto[:2000]}
            ---
            """
            response = await asyncio.to_thread(
                self.client.chat.completions.create,
                model="deepseek-chat",
                messages=[{"role": "user", "content": prompt}],
                max_tokens=10,
                temperature=0.0
            )
            resposta = response.choices[0].message.content.strip().upper()
            return "SIM" in resposta
        except Exception as e:
            print(f"‚ö†Ô∏è Erro na valida√ß√£o com IA: {e}")
            return False

    async def _extrair_e_validar_async(self, session, url: str, termo_pesquisa: str) -> Dict[str, Any]:
        """Extrai o conte√∫do de uma URL e depois valida sua relev√¢ncia com a IA."""
        print(f"‚Üí Tentando extrair de: {url}")
        try:
            request_headers = self.headers.copy()
            request_headers['User-Agent'] = random.choice(self.user_agents)
            request_headers['Referer'] = 'https://www.google.com/'

            async with session.get(url, headers=request_headers, timeout=15, ssl=False) as response:
                if response.status == 200:
                    raw_html = await response.read()
                    html = raw_html.decode('utf-8', errors='ignore')
                    soup = BeautifulSoup(html, 'html.parser')
                    for tag in soup.find_all(['script', 'style', 'nav', 'footer', 'header', 'aside']):
                        tag.decompose()
                    
                    texto = soup.body.get_text(separator=' ', strip=True) if soup.body else ""
                    texto_limpo = re.sub(r'\s+', ' ', texto).strip()
                    
                    if len(texto_limpo) < self.config['tamanho_minimo_conteudo']:
                        print(f"‚ö†Ô∏è Descartado (curto): {url}")
                        return None

                    print(f"  -> Validando relev√¢ncia do conte√∫do com IA...")
                    if await self._validar_relevancia_com_ia_async(texto_limpo, termo_pesquisa):
                        print(f"‚úî SUCESSO (IA APROVOU): Conte√∫do extra√≠do de {url} ({len(texto_limpo)} caracteres)")
                        # COMENT√ÅRIO: Retorna o 'texto_limpo' completo, sem limitar o tamanho.
                        return { "url": url, "texto": texto_limpo, "titulo": soup.title.string.strip() if soup.title else "N/A" }
                    else:
                        print(f"‚ö†Ô∏è Descartado (IA Reprovou como irrelevante): {url}")
                        return None
                else:
                    print(f"‚ùå Falha (Status {response.status}): {url}")
                    return None
        except Exception as e:
            print(f"‚ùå Falha (Erro: {type(e).__name__}): {url}")
            return None

    async def _pesquisar_dominio_async(self, session, termo: str, dominio: str) -> List[Dict[str, Any]]:
        """Pesquisa um termo espec√≠fico dentro de um √∫nico dom√≠nio."""
        query = f'jurisprud√™ncia ementa ac√≥rd√£o sobre "{termo}" site:{dominio}'
        resultados_sucesso = []
        try:
            loop = asyncio.get_event_loop()
            urls_encontradas = await loop.run_in_executor(None, lambda: list(search(query, num_results=self.config['search_results_per_domain'], lang="pt")))
            
            tasks = [self._extrair_e_validar_async(session, url, termo) for url in urls_encontradas]
            resultados_tasks = await asyncio.gather(*tasks)
            
            resultados_sucesso = [res for res in resultados_tasks if res]
            return resultados_sucesso
        except Exception as e:
            print(f"‚ö†Ô∏è Falha cr√≠tica na busca do Google para o dom√≠nio {dominio}: {e}")
            return []

    async def _pesquisar_termo_async(self, termo: str) -> List[Dict[str, Any]]:
        """
        COMENT√ÅRIO: A l√≥gica foi reescrita. Agora, ele cria uma tarefa de pesquisa para cada
        dom√≠nio priorit√°rio e as executa em paralelo, garantindo que todos sejam tentados.
        """
        print(f"\nüìö Buscando jurisprud√™ncia para o termo: '{termo}' em todos os dom√≠nios priorit√°rios...")
        
        async with aiohttp.ClientSession() as session:
            tasks = [self._pesquisar_dominio_async(session, termo, site) for site in self.sites_prioritarios]
            resultados_por_dominio = await asyncio.gather(*tasks)
        
        # Junta os resultados de todos os dom√≠nios em uma √∫nica lista
        todos_os_resultados = [item for sublist in resultados_por_dominio for item in sublist]
        
        print(f"üéØ Pesquisa para '{termo}' conclu√≠da com {len(todos_os_resultados)} extra√ß√µes bem-sucedidas no total.")
        return todos_os_resultados

    async def pesquisar_jurisprudencia_async(self, termos: List[str]) -> List[Dict[str, Any]]:
        """Cria e executa todas as tarefas de pesquisa em paralelo."""
        tasks = [self._pesquisar_termo_async(termo) for termo in termos]
        resultados_por_termo = await asyncio.gather(*tasks)
        
        todos_os_resultados = [item for sublist in resultados_por_termo for item in sublist]
        return todos_os_resultados

    def pesquisar(self, termos: List[str]) -> List[Dict[str, Any]]:
        """Ponto de entrada s√≠ncrono que executa a l√≥gica ass√≠ncrona."""
        inicio_pesquisa = datetime.now()
        try:
            resultado = asyncio.run(self.pesquisar_jurisprudencia_async(termos))
        except Exception as e:
            print(f"‚ùå Erro cr√≠tico durante a pesquisa de jurisprud√™ncia: {e}")
            return []
        
        tempo_total = (datetime.now() - inicio_pesquisa).total_seconds()
        print(f"\n--- RESUMO DA PESQUISA DE JURISPRUD√äNCIA ---")
        print(f"‚úÖ Total de {len(resultado)} conte√∫dos relevantes encontrados.")
        print(f"‚úÖ PESQUISA CONCLU√çDA em {tempo_total:.1f} segundos\n")
        return resultado
